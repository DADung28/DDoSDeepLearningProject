{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 14:09:30,061\tINFO worker.py:1636 -- Started a local Ray instance.\n",
      "2023-07-17 14:09:34.984238: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import library for load data\n",
    "import ray\n",
    "ray.init(num_cpus=20)\n",
    "import modin.pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from category_encoders import OrdinalEncoder\n",
    "from numpy import genfromtxt\n",
    "import sys\n",
    "import csv\n",
    "# Import deeplearning library\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms \n",
    "from torch.utils.data import Dataset\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CUDA device \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------ANALYZE DATASET-------------\n",
      "Loading dataset, please wait .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: When using a pre-initialized Ray cluster, please ensure that the runtime env sets environment variable __MODIN_AUTOIMPORT_PANDAS__ to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "print('-------------ANALYZE DATASET-------------')\n",
    "#Load dataset\n",
    "print(\"Loading dataset, please wait .....\")\n",
    "train = pd.read_csv('/home/jun/CICIDS2019/TrainCIC2019.csv')\n",
    "#test = pd.read_csv('/home/jun/CICIDS2019/TestCIC2019.csv')\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns name of dataset is contain space, this function will strip it out (data = fix_columns_name(data))\n",
    "def fix_columns_name(data):\n",
    "    data.columns = [column_name.strip() for column_name in data.columns]\n",
    "    return data\n",
    "\n",
    "# Drop all string data in dataset (data = drop_non_numberic_columns(data))\n",
    "def drop_non_numberic_columns(data):\n",
    "    data.drop(['Unnamed: 0', 'Flow ID','Source IP','Destination IP', 'Timestamp', 'SimillarHTTP'], inplace=True, axis=1)\n",
    "    return data\n",
    "\n",
    "#Create a copy of pandas frame with dropped NaN and Inf value (data = drop_NaN(data))\n",
    "def drop_NaN(data):\n",
    "    dropped = data.copy(deep=True)\n",
    "    dropped.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    dropped.dropna(inplace=True)\n",
    "    return dropped\n",
    "\n",
    "# Return a dictionary of available labels and it number from dataset 'Label' column (labels_dict = available_lable(data))\n",
    "# Input: dataset\n",
    "# Output: \n",
    "# Traning dataset: {'Syn': 0, 'DrDoS_SNMP': 1, 'DrDoS_UDP': 2, 'DrDoS_DNS': 3, 'TFTP': 4, 'DrDoS_LDAP': 5, 'UDP-lag': 6, 'DrDoS_NTP': 7, 'DrDoS_MSSQL': 8, 'DrDoS_NetBIOS': 9, 'BENIGN': 10, 'WebDDoS': 11, 'DrDoS_SSDP': 12}\n",
    "# Testing dataset {'Syn': 0, 'NetBIOS': 1, 'UDPLag': 2, 'LDAP': 3, 'MSSQL': 4, 'BENIGN': 5, 'Portmap': 6, 'UDP': 7} \n",
    "def available_label(data):\n",
    "    data_labels = set(data['Label'])\n",
    "    labels_dict = {}\n",
    "    for i, label in enumerate(data_labels):\n",
    "        labels_dict.update({label:i})\n",
    "    return labels_dict\n",
    "\n",
    "# Caculate flow labels number and return dictionary of {labels : count}\n",
    "# train_flow_labels_count = flow_labels_count(data)\n",
    "def flows_labels_count(data):\n",
    "    labels = {}\n",
    "    for flow_label in data['Label']:\n",
    "        if flow_label in labels.keys():\n",
    "            labels[flow_label] += 1\n",
    "        else:\n",
    "            labels[flow_label] = 0\n",
    "    return labels\n",
    "\n",
    "# Encoding labels to assigned number for learning\n",
    "# data = encoding_lables('train', data)\n",
    "def encoding_labels(dataset_type, data):\n",
    "    if dataset_type == 'train':\n",
    "        labels_num = {'Syn': 0, 'DrDoS_SNMP': 1, 'DrDoS_UDP': 2, 'DrDoS_DNS': 3, 'TFTP': 4, 'DrDoS_LDAP': 5, 'UDP-lag': 6, 'DrDoS_NTP': 7, 'DrDoS_MSSQL': 8, 'DrDoS_NetBIOS': 9, 'BENIGN': 10, 'WebDDoS': 11, 'DrDoS_SSDP': 12}\n",
    "    elif dataset_type == 'test':\n",
    "        labels_num = {'Syn': 0, 'NetBIOS': 9, 'UDPLag': 6, 'LDAP': 5, 'MSSQL': 8, 'BENIGN': 10, 'Portmap': 13, 'UDP': 6} \n",
    "    for label, number in labels_num.items():\n",
    "        data['Label'] = data['Label'].replace(label, number)\n",
    "    return data\n",
    "\n",
    "# Ploting data\n",
    "def data_plot(data):\n",
    "    data_flow_labels_count = flows_labels_count(data)\n",
    "    for flow_label, flow_number in data_flow_labels_count.items():\n",
    "        print('Number of {} flow is: {}/{} ({:.2f})'.format(flow_label, flow_number, sum(data_flow_labels_count.values()), flow_number/sum(data_flow_labels_count.values())*100))\n",
    "    #Create Flow Number based on label Figure\n",
    "    data_flows_figure_num = plt.figure(figsize = (20, 5))\n",
    "    # creating the bar plot\n",
    "    plt.bar(data_flow_labels_count.keys(), data_flow_labels_count.values(), color ='red',\n",
    "            width = 0.5)\n",
    "    plt.xlabel(\"Flows Label\")\n",
    "    plt.ylabel(\"Number of FLows\")\n",
    "    plt.title(\"Flows label and number\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix columns name\n",
    "train = fix_columns_name(train)\n",
    "#test = fix_columns_name(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available labels of training data set: {'DrDoS_SNMP': 0, 'DrDoS_NTP': 1, 'DrDoS_DNS': 2, 'DrDoS_MSSQL': 3, 'DrDoS_SSDP': 4, 'BENIGN': 5, 'TFTP': 6, 'DrDoS_UDP': 7, 'DrDoS_LDAP': 8, 'Syn': 9, 'DrDoS_NetBIOS': 10, 'UDP-lag': 11, 'WebDDoS': 12}\n"
     ]
    }
   ],
   "source": [
    "# Get dictionary of available labels in data\n",
    "print('Available labels of training data set:', available_label(train))\n",
    "#print('Available labels of testing data set:', available_label(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset: Contain NaN values columns: ['Flow Bytes/s']\n",
      "Train Dataset Contain infinity values columns: ['Flow Bytes/s', 'Flow Packets/s']\n"
     ]
    }
   ],
   "source": [
    "#Check for NaN and Inf Columnns\n",
    "print(\"Train Dataset: Contain NaN values columns:\", train.columns[train.isna().any()].tolist())\n",
    "print(\"Train Dataset Contain infinity values columns:\", train.columns[train.isin([np.inf, -np.inf]).any()].tolist())\n",
    "#print(\"Test Dataset: Contain NaN values columns:\", test.columns[test.isna().any()].tolist())\n",
    "#print(\"Test Dataset Contain infinity values columns:\", test.columns[test.isin([np.inf, -np.inf]).any()].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data plot\n",
      "Number of DrDoS_DNS flow is: 5071010/50063099 (10.13)\n",
      "Number of BENIGN flow is: 56862/50063099 (0.11)\n",
      "Number of DrDoS_LDAP flow is: 2179929/50063099 (4.35)\n",
      "Number of DrDoS_MSSQL flow is: 4522491/50063099 (9.03)\n",
      "Number of DrDoS_NetBIOS flow is: 4093278/50063099 (8.18)\n",
      "Number of DrDoS_NTP flow is: 1202641/50063099 (2.40)\n",
      "Number of DrDoS_SNMP flow is: 5159869/50063099 (10.31)\n",
      "Number of DrDoS_SSDP flow is: 2610610/50063099 (5.21)\n",
      "Number of DrDoS_UDP flow is: 3134644/50063099 (6.26)\n",
      "Number of Syn flow is: 1582288/50063099 (3.16)\n",
      "Number of TFTP flow is: 20082579/50063099 (40.11)\n",
      "Number of UDP-lag flow is: 366460/50063099 (0.73)\n",
      "Number of WebDDoS flow is: 438/50063099 (0.00)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Traing data plot\n",
    "print('Training data plot')\n",
    "data_plot(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing data plot\n",
    "#Traing data plot\n",
    "#print('Testing data plot')\n",
    "#data_plot(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test labels count before drop NaN and inf\n",
    "train_flow_labels_count = flows_labels_count(train)\n",
    "#test_flow_labels_count = flows_labels_count(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN and inf\n",
    "train = drop_NaN(train)\n",
    "#test = drop_NaN(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test labels count after drop NaN and inf\n",
    "train_dropped_flow_labels_count = flows_labels_count(train)\n",
    "#test_dropped_flow_labels_count = flows_labels_count(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(DrDoS_DNS) Dropped train flow number is: 162346 (3.31%)\n",
      "(BENIGN) Dropped train flow number is: 438 (0.78%)\n",
      "(DrDoS_LDAP) Dropped train flow number is: 38630 (1.80%)\n",
      "(DrDoS_MSSQL) Dropped train flow number is: 126446 (2.88%)\n",
      "(DrDoS_NetBIOS) Dropped train flow number is: 129833 (3.28%)\n",
      "(DrDoS_NTP) Dropped train flow number is: 6952 (0.58%)\n",
      "(DrDoS_SNMP) Dropped train flow number is: 10609 (0.21%)\n",
      "(DrDoS_SSDP) Dropped train flow number is: 42042 (1.64%)\n",
      "(DrDoS_UDP) Dropped train flow number is: 40643 (1.31%)\n",
      "(Syn) Dropped train flow number is: 202306 (14.66%)\n",
      "(TFTP) Dropped train flow number is: 566609 (2.90%)\n",
      "(UDP-lag) Dropped train flow number is: 36382 (11.02%)\n",
      "(WebDDoS) Dropped train flow number is: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# Get train dataset dropped labels number\n",
    "for flow_label, flow_number in train_dropped_flow_labels_count.items():\n",
    "    print('({}) Dropped train flow number is: {} ({:.2f}%)'.format(flow_label, -flow_number + train_flow_labels_count[flow_label], (-flow_number + train_flow_labels_count[flow_label])/flow_number*100))\n",
    "# Get test dataset dropped labels number\n",
    "#for flow_label, flow_number in test_dropped_flow_labels_count.items():\n",
    "#    print('({}) Dropped test flow number is: {} ({:.2f}%)'.format(flow_label, -flow_number + test_flow_labels_count[flow_label], (-flow_number + test_flow_labels_count[flow_label])/flow_number*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0 : 425\n",
      "Flow ID : 172.16.0.5-192.168.50.1-634-60495-17\n",
      "Source IP : 172.16.0.5\n",
      "Source Port : 634\n",
      "Destination IP : 192.168.50.1\n",
      "Destination Port : 60495\n",
      "Protocol : 17\n",
      "Timestamp : 2018-12-01 10:51:39.813448\n",
      "Flow Duration : 28415\n",
      "Total Fwd Packets : 97\n",
      "Total Backward Packets : 0\n",
      "Total Length of Fwd Packets : 42680.0\n",
      "Total Length of Bwd Packets : 0.0\n",
      "Fwd Packet Length Max : 440.0\n",
      "Fwd Packet Length Min : 440.0\n",
      "Fwd Packet Length Mean : 440.0\n",
      "Fwd Packet Length Std : 0.0\n",
      "Bwd Packet Length Max : 0.0\n",
      "Bwd Packet Length Min : 0.0\n",
      "Bwd Packet Length Mean : 0.0\n",
      "Bwd Packet Length Std : 0.0\n",
      "Flow Bytes/s : 1502023.5790955485\n",
      "Flow Packets/s : 3413.689952489882\n",
      "Flow IAT Mean : 295.98958333333337\n",
      "Flow IAT Std : 500.95930068517794\n",
      "Flow IAT Max : 3596.0\n",
      "Flow IAT Min : 1.0\n",
      "Fwd IAT Total : 28415.0\n",
      "Fwd IAT Mean : 295.98958333333337\n",
      "Fwd IAT Std : 500.95930068517794\n",
      "Fwd IAT Max : 3596.0\n",
      "Fwd IAT Min : 1.0\n",
      "Bwd IAT Total : 0.0\n",
      "Bwd IAT Mean : 0.0\n",
      "Bwd IAT Std : 0.0\n",
      "Bwd IAT Max : 0.0\n",
      "Bwd IAT Min : 0.0\n",
      "Fwd PSH Flags : 0.0\n",
      "Bwd PSH Flags : 0.0\n",
      "Fwd URG Flags : 0.0\n",
      "Bwd URG Flags : 0.0\n",
      "Fwd Header Length : -97.0\n",
      "Bwd Header Length : 0.0\n",
      "Fwd Packets/s : 3413.689952489882\n",
      "Bwd Packets/s : 0.0\n",
      "Min Packet Length : 440.0\n",
      "Max Packet Length : 440.0\n",
      "Packet Length Mean : 440.0\n",
      "Packet Length Std : 0.0\n",
      "Packet Length Variance : 0.0\n",
      "FIN Flag Count : 0.0\n",
      "SYN Flag Count : 0.0\n",
      "RST Flag Count : 0.0\n",
      "PSH Flag Count : 0.0\n",
      "ACK Flag Count : 0.0\n",
      "URG Flag Count : 0.0\n",
      "CWE Flag Count : 0.0\n",
      "ECE Flag Count : 0.0\n",
      "Down/Up Ratio : 0.0\n",
      "Average Packet Size : 444.5360824742268\n",
      "Avg Fwd Segment Size : 440.0\n",
      "Avg Bwd Segment Size : 0.0\n",
      "Fwd Header Length.1 : -97.0\n",
      "Fwd Avg Bytes/Bulk : 0.0\n",
      "Fwd Avg Packets/Bulk : 0\n",
      "Fwd Avg Bulk Rate : 0\n",
      "Bwd Avg Bytes/Bulk : 0\n",
      "Bwd Avg Packets/Bulk : 0\n",
      "Bwd Avg Bulk Rate : 0\n",
      "Subflow Fwd Packets : 97\n",
      "Subflow Fwd Bytes : 42680\n",
      "Subflow Bwd Packets : 0\n",
      "Subflow Bwd Bytes : 0\n",
      "Init_Win_bytes_forward : -1\n",
      "Init_Win_bytes_backward : -1\n",
      "act_data_pkt_fwd : 96\n",
      "min_seg_size_forward : -1\n",
      "Active Mean : 0.0\n",
      "Active Std : 0.0\n",
      "Active Max : 0.0\n",
      "Active Min : 0.0\n",
      "Idle Mean : 0.0\n",
      "Idle Std : 0.0\n",
      "Idle Max : 0.0\n",
      "Idle Min : 0.0\n",
      "SimillarHTTP : 0\n",
      "Inbound : 1\n",
      "Label : DrDoS_DNS\n"
     ]
    }
   ],
   "source": [
    "row_sample = train.iloc[0]\n",
    "columns = list(train.columns)\n",
    "for i, data in enumerate(row_sample):\n",
    "    print(columns[i],':',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding train dataset label\n",
    "train = encoding_labels('train', train)\n",
    "#test = encoding_labels('test', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop num numberic columns ('Flow ID','Source IP','Destination IP', 'Timestamp', 'SimillarHTTP')\n",
    "train = drop_non_numberic_columns(train)\n",
    "#test = drop_non_numberic_columns(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Source Port  Destination Port  Protocol  Flow Duration  \\\n",
      "0                 634             60495        17          28415   \n",
      "1                 634             60495        17              2   \n",
      "2                 634             46391        17          48549   \n",
      "3                 634             11894        17          48337   \n",
      "4                 634             27878        17          32026   \n",
      "...               ...               ...       ...            ...   \n",
      "50063106        60489             27808         6              1   \n",
      "50063107        60490             14102         6              1   \n",
      "50063108        60491             58360         6              1   \n",
      "50063109        60492              2905         6              2   \n",
      "50063111        60494             44935         6            134   \n",
      "\n",
      "          Total Fwd Packets  Total Backward Packets  \\\n",
      "0                        97                       0   \n",
      "1                         2                       0   \n",
      "2                       200                       0   \n",
      "3                       200                       0   \n",
      "4                       200                       0   \n",
      "...                     ...                     ...   \n",
      "50063106                  2                       0   \n",
      "50063107                  2                       0   \n",
      "50063108                  2                       0   \n",
      "50063109                  2                       0   \n",
      "50063111                  2                       2   \n",
      "\n",
      "          Total Length of Fwd Packets  Total Length of Bwd Packets  \\\n",
      "0                             42680.0                          0.0   \n",
      "1                               880.0                          0.0   \n",
      "2                             88000.0                          0.0   \n",
      "3                             88000.0                          0.0   \n",
      "4                             88000.0                          0.0   \n",
      "...                               ...                          ...   \n",
      "50063106                          0.0                          0.0   \n",
      "50063107                          0.0                          0.0   \n",
      "50063108                          0.0                          0.0   \n",
      "50063109                          0.0                          0.0   \n",
      "50063111                          0.0                          0.0   \n",
      "\n",
      "          Fwd Packet Length Max  Fwd Packet Length Min  ...  Active Mean  \\\n",
      "0                         440.0                  440.0  ...          0.0   \n",
      "1                         440.0                  440.0  ...          0.0   \n",
      "2                         440.0                  440.0  ...          0.0   \n",
      "3                         440.0                  440.0  ...          0.0   \n",
      "4                         440.0                  440.0  ...          0.0   \n",
      "...                         ...                    ...  ...          ...   \n",
      "50063106                    0.0                    0.0  ...          0.0   \n",
      "50063107                    0.0                    0.0  ...          0.0   \n",
      "50063108                    0.0                    0.0  ...          0.0   \n",
      "50063109                    0.0                    0.0  ...          0.0   \n",
      "50063111                    0.0                    0.0  ...          0.0   \n",
      "\n",
      "          Active Std  Active Max  Active Min  Idle Mean  Idle Std  Idle Max  \\\n",
      "0                0.0         0.0         0.0        0.0       0.0       0.0   \n",
      "1                0.0         0.0         0.0        0.0       0.0       0.0   \n",
      "2                0.0         0.0         0.0        0.0       0.0       0.0   \n",
      "3                0.0         0.0         0.0        0.0       0.0       0.0   \n",
      "4                0.0         0.0         0.0        0.0       0.0       0.0   \n",
      "...              ...         ...         ...        ...       ...       ...   \n",
      "50063106         0.0         0.0         0.0        0.0       0.0       0.0   \n",
      "50063107         0.0         0.0         0.0        0.0       0.0       0.0   \n",
      "50063108         0.0         0.0         0.0        0.0       0.0       0.0   \n",
      "50063109         0.0         0.0         0.0        0.0       0.0       0.0   \n",
      "50063111         0.0         0.0         0.0        0.0       0.0       0.0   \n",
      "\n",
      "          Idle Min  Inbound  Label  \n",
      "0              0.0        1      3  \n",
      "1              0.0        0      3  \n",
      "2              0.0        1      3  \n",
      "3              0.0        1      3  \n",
      "4              0.0        1      3  \n",
      "...            ...      ...    ...  \n",
      "50063106       0.0        1      6  \n",
      "50063107       0.0        1      6  \n",
      "50063108       0.0        1      6  \n",
      "50063109       0.0        1      6  \n",
      "50063111       0.0        1      6  \n",
      "\n",
      "[48699876 rows x 82 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 3319 MiB, 9 objects, write throughput 993 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n",
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 6898 MiB, 18 objects, write throughput 1297 MiB/s.\n",
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 11292 MiB, 46 objects, write throughput 1076 MiB/s.\n"
     ]
    }
   ],
   "source": [
    "#Shuffle data for training \n",
    "train = train.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 16653 MiB, 81 objects, write throughput 1075 MiB/s.\n",
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 65721 MiB, 251 objects, write throughput 2429 MiB/s.\n",
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 66222 MiB, 252 objects, write throughput 2381 MiB/s.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-07-17 14:17:27,637 E 1673960 1673973] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-07-17_14-09-28_263214_1660541 is over 95% full, available space: 13390778368; capacity: 269702828032. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-07-17 14:17:37,656 E 1673960 1673973] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-07-17_14-09-28_263214_1660541 is over 95% full, available space: 1237012480; capacity: 269702828032. Object creation will fail if spilling is required.\n",
      "2023-07-17 14:17:41,927\tWARNING worker.py:2019 -- Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1911, in ray._raylet.spill_objects_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1914, in ray._raylet.spill_objects_handler\n",
      "  File \"/home/jun/miniconda3/envs/py311/lib/python3.11/site-packages/ray/_private/external_storage.py\", line 668, in spill_objects\n",
      "    return _external_storage.spill_objects(object_refs, owner_addresses)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jun/miniconda3/envs/py311/lib/python3.11/site-packages/ray/_private/external_storage.py\", line 305, in spill_objects\n",
      "    return self._write_multiple_objects(f, object_refs, owner_addresses, url)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jun/miniconda3/envs/py311/lib/python3.11/site-packages/ray/_private/external_storage.py\", line 149, in _write_multiple_objects\n",
      "    written_bytes = f.write(payload)\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "OSError: [Errno 28] No space left on device\n",
      "An unexpected internal error occurred while the IO worker was spilling objects: [Errno 28] No space left on device\n"
     ]
    }
   ],
   "source": [
    "# Change data to numpy\n",
    "train_day = train.to_numpy()\n",
    "#test_day = test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt('/disk2/jun/TrainCICIDS2019_np.csv', train_day, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_day_X = train_day[:, :81]\n",
    "train_day_y = train_day[:, 81]\n",
    "#test_day_X = test_day[:, :81]\n",
    "#test_day_y = test_day[:, 81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data to range (0, 1)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_day_X)\n",
    "train_normalized = scaler.transform(train_day_X)\n",
    "#scaler.fit(test_day_X)\n",
    "#train_normalized = scaler.transform(test_day_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slit training day data to train and test\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(train_day_X, train_day_y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.999, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (38959900, 81), y_train shape: (38959900,)\n",
      "X_val shape: (9739, 81), y_val shape: (9739,)\n",
      "X_test shape: (9730237, 81), y_test shape: (9730237,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape: {}, y_train shape: {}'.format(X_train.shape, y_train.shape))\n",
    "print('X_val shape: {}, y_val shape: {}'.format(X_val.shape, y_val.shape))\n",
    "print('X_test shape: {}, y_test shape: {}'.format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Deeplearning parameters\n",
    "batch_size = 100000\n",
    "learning_rate = 0.005\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.from_numpy(data)\n",
    "        self.labels = torch.from_numpy(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "\n",
    "Train_dataset = MyDataset(X_train.astype(np.float32), y_train.astype(np.float32))\n",
    "Val_dataset = MyDataset(X_val.astype(np.float32), y_val.astype(np.float32))\n",
    "Test_dataset = MyDataset(X_test.astype(np.float32), y_test.astype(np.float32))\n",
    "\n",
    "# Create a data loader for batch training\n",
    "train_loader = torch.utils.data.DataLoader(Train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(Val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(Test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Model\n",
    "# ANN (inputs_size = 81, 128, 256, 512, 256, 128, 13)\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(81, 128)\n",
    "        self.l2 = nn.Linear(128, 256)\n",
    "        self.l3 = nn.Linear(256, 512)\n",
    "        self.l4 = nn.Linear(512, 256)\n",
    "        self.l5 = nn.Linear(256, 128)\n",
    "        self.l6 = nn.Linear(128, 13)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.l4(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.l5(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.l6(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_loss_acc(net, criterion, data_loader):\n",
    "  \"\"\"A simple function that iterates over `data_loader` to calculate the overall loss\"\"\"\n",
    "  testing_loss = []\n",
    "  testing_acc = []\n",
    "  avg_loss = 0\n",
    "  arg_acc = 0\n",
    "  with torch.no_grad():\n",
    "    for data in data_loader:\n",
    "      inputs, labels = data\n",
    "      # get the data to GPU (if available)\n",
    "      inputs, labels = inputs.to(device), labels.to(device, dtype = torch.long) # Change to data type long to not rise error\n",
    "      outputs = net(inputs)\n",
    "      # calculate the loss for this batch\n",
    "      loss = criterion(outputs, labels)\n",
    "      # add the loss of this batch to the list\n",
    "      testing_loss.append(loss.item())\n",
    "      _, predicted = torch.max(outputs, 1) # Get prediction on batch (shape: batch_size)\n",
    "      batch_correct_predicted = (predicted == labels).sum().item() # Get number of true prediction on batch\n",
    "      testing_acc.append(batch_correct_predicted/batch_size*100) # Append prediction accuracy of this batch\n",
    "  avg_loss = np.mean(testing_loss) \n",
    "  avg_acc = np.mean(testing_acc) \n",
    "      \n",
    "  # calculate the average loss\n",
    "  return {'loss': avg_loss, 'acc': avg_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (l1): Linear(in_features=81, out_features=128, bias=True)\n",
       "  (l2): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (l3): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (l4): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (l5): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (l6): Linear(in_features=128, out_features=13, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNet()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('/home/jun/CICIDS2019/ANN.csv', 'w')\n",
    "writer = csv.writer(f)\n",
    "header = ['10000 batch', 'train_loss', 'train_acc', 'test_loss', 'test_acc']\n",
    "writer.writerow(header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/100, step [1/390], train_loss = 525596.000, train_acc = 6.987\n",
      "epoch 1/100, step [2/390], train_loss = 112702.148, train_acc = 8.057\n",
      "epoch 1/100, step [3/390], train_loss = 59288.746, train_acc = 7.681\n",
      "epoch 1/100, step [4/390], train_loss = 15413.145, train_acc = 5.723\n",
      "epoch 1/100, step [5/390], train_loss = 409.819, train_acc = 6.196\n",
      "epoch 1/100, step [6/390], train_loss = 9.318, train_acc = 6.351\n",
      "epoch 1/100, step [7/390], train_loss = 7.631, train_acc = 7.015\n",
      "epoch 1/100, step [8/390], train_loss = 7.907, train_acc = 12.139\n",
      "epoch 1/100, step [9/390], train_loss = 3.782, train_acc = 22.854\n",
      "epoch 1/100, step [10/390], train_loss = 3.714, train_acc = 31.344\n",
      "epoch 1/100, step [11/390], train_loss = 2.549, train_acc = 36.233\n",
      "epoch 1/100, step [12/390], train_loss = 2.464, train_acc = 38.533\n",
      "epoch 1/100, step [13/390], train_loss = 2.454, train_acc = 39.330\n",
      "epoch 1/100, step [14/390], train_loss = 2.444, train_acc = 39.885\n",
      "epoch 1/100, step [15/390], train_loss = 2.433, train_acc = 40.058\n",
      "epoch 1/100, step [16/390], train_loss = 2.422, train_acc = 39.992\n",
      "epoch 1/100, step [17/390], train_loss = 2.411, train_acc = 40.246\n",
      "epoch 1/100, step [18/390], train_loss = 2.402, train_acc = 39.975\n",
      "epoch 1/100, step [19/390], train_loss = 2.392, train_acc = 39.890\n",
      "epoch 1/100, step [20/390], train_loss = 2.381, train_acc = 40.146\n",
      "epoch 1/100, step [21/390], train_loss = 2.371, train_acc = 39.903\n",
      "epoch 1/100, step [22/390], train_loss = 2.361, train_acc = 39.970\n",
      "epoch 1/100, step [23/390], train_loss = 2.351, train_acc = 40.075\n",
      "epoch 1/100, step [24/390], train_loss = 2.340, train_acc = 40.159\n",
      "epoch 1/100, step [25/390], train_loss = 2.338, train_acc = 40.177\n",
      "epoch 1/100, step [26/390], train_loss = 2.323, train_acc = 39.924\n",
      "epoch 1/100, step [27/390], train_loss = 2.314, train_acc = 39.999\n",
      "epoch 1/100, step [28/390], train_loss = 2.304, train_acc = 40.238\n",
      "epoch 1/100, step [29/390], train_loss = 2.295, train_acc = 39.952\n",
      "epoch 1/100, step [30/390], train_loss = 2.288, train_acc = 39.717\n",
      "epoch 1/100, step [31/390], train_loss = 2.277, train_acc = 40.088\n",
      "epoch 1/100, step [32/390], train_loss = 2.269, train_acc = 40.332\n",
      "epoch 1/100, step [33/390], train_loss = 2.262, train_acc = 39.884\n",
      "epoch 1/100, step [34/390], train_loss = 2.252, train_acc = 40.165\n",
      "epoch 1/100, step [35/390], train_loss = 2.243, train_acc = 40.286\n",
      "epoch 1/100, step [36/390], train_loss = 2.361, train_acc = 39.972\n",
      "epoch 1/100, step [37/390], train_loss = 2.230, train_acc = 39.983\n",
      "epoch 1/100, step [38/390], train_loss = 2.223, train_acc = 40.007\n",
      "epoch 1/100, step [39/390], train_loss = 2.214, train_acc = 40.185\n",
      "epoch 1/100, step [40/390], train_loss = 2.206, train_acc = 40.272\n",
      "epoch 1/100, step [41/390], train_loss = 2.203, train_acc = 39.741\n",
      "epoch 1/100, step [42/390], train_loss = 2.193, train_acc = 40.355\n",
      "epoch 1/100, step [43/390], train_loss = 2.189, train_acc = 39.832\n",
      "epoch 1/100, step [44/390], train_loss = 2.184, train_acc = 39.956\n",
      "epoch 1/100, step [45/390], train_loss = 2.174, train_acc = 40.287\n",
      "epoch 1/100, step [46/390], train_loss = 2.171, train_acc = 39.910\n",
      "epoch 1/100, step [47/390], train_loss = 2.164, train_acc = 40.017\n",
      "epoch 1/100, step [48/390], train_loss = 2.160, train_acc = 39.972\n",
      "epoch 1/100, step [49/390], train_loss = 2.156, train_acc = 40.089\n",
      "epoch 1/100, step [50/390], train_loss = 2.149, train_acc = 39.974\n",
      "epoch 1/100, step [51/390], train_loss = 2.140, train_acc = 40.360\n",
      "epoch 1/100, step [52/390], train_loss = 2.138, train_acc = 40.034\n",
      "epoch 1/100, step [53/390], train_loss = 2.133, train_acc = 40.127\n",
      "epoch 1/100, step [54/390], train_loss = 2.129, train_acc = 40.084\n",
      "epoch 1/100, step [55/390], train_loss = 2.124, train_acc = 40.132\n",
      "epoch 1/100, step [56/390], train_loss = 2.120, train_acc = 39.963\n",
      "epoch 1/100, step [57/390], train_loss = 2.116, train_acc = 40.005\n",
      "epoch 1/100, step [58/390], train_loss = 2.115, train_acc = 40.002\n",
      "epoch 1/100, step [59/390], train_loss = 2.107, train_acc = 39.938\n",
      "epoch 1/100, step [60/390], train_loss = 2.101, train_acc = 40.247\n",
      "epoch 1/100, step [61/390], train_loss = 2.097, train_acc = 40.156\n",
      "epoch 1/100, step [62/390], train_loss = 2.092, train_acc = 40.184\n",
      "epoch 1/100, step [63/390], train_loss = 2.088, train_acc = 40.519\n",
      "epoch 1/100, step [64/390], train_loss = 2.089, train_acc = 39.940\n",
      "epoch 1/100, step [65/390], train_loss = 2.085, train_acc = 39.892\n",
      "epoch 1/100, step [66/390], train_loss = 2.080, train_acc = 40.197\n",
      "epoch 1/100, step [67/390], train_loss = 2.080, train_acc = 39.933\n",
      "epoch 1/100, step [68/390], train_loss = 2.077, train_acc = 39.906\n",
      "epoch 1/100, step [69/390], train_loss = 2.077, train_acc = 39.760\n",
      "epoch 1/100, step [70/390], train_loss = 2.070, train_acc = 39.973\n",
      "epoch 1/100, step [71/390], train_loss = 2.068, train_acc = 39.979\n",
      "epoch 1/100, step [72/390], train_loss = 2.065, train_acc = 39.937\n",
      "epoch 1/100, step [73/390], train_loss = 2.060, train_acc = 40.122\n",
      "epoch 1/100, step [74/390], train_loss = 2.062, train_acc = 39.810\n",
      "epoch 1/100, step [75/390], train_loss = 2.058, train_acc = 39.845\n",
      "epoch 1/100, step [76/390], train_loss = 2.056, train_acc = 39.916\n",
      "epoch 1/100, step [77/390], train_loss = 2.051, train_acc = 40.094\n",
      "epoch 1/100, step [78/390], train_loss = 2.049, train_acc = 40.080\n",
      "epoch 1/100, step [79/390], train_loss = 2.048, train_acc = 39.984\n",
      "epoch 1/100, step [80/390], train_loss = 2.049, train_acc = 39.868\n",
      "epoch 1/100, step [81/390], train_loss = 2.043, train_acc = 40.055\n",
      "epoch 1/100, step [82/390], train_loss = 2.043, train_acc = 39.985\n",
      "epoch 1/100, step [83/390], train_loss = 2.044, train_acc = 39.716\n",
      "epoch 1/100, step [84/390], train_loss = 2.035, train_acc = 40.194\n",
      "epoch 1/100, step [85/390], train_loss = 2.032, train_acc = 40.332\n",
      "epoch 1/100, step [86/390], train_loss = 2.031, train_acc = 40.256\n",
      "epoch 1/100, step [87/390], train_loss = 2.032, train_acc = 40.115\n",
      "epoch 1/100, step [88/390], train_loss = 2.032, train_acc = 40.042\n",
      "epoch 1/100, step [89/390], train_loss = 2.027, train_acc = 40.096\n",
      "epoch 1/100, step [90/390], train_loss = 2.027, train_acc = 40.063\n",
      "epoch 1/100, step [91/390], train_loss = 2.028, train_acc = 39.960\n",
      "epoch 1/100, step [92/390], train_loss = 2.026, train_acc = 40.009\n",
      "epoch 1/100, step [93/390], train_loss = 2.020, train_acc = 40.189\n",
      "epoch 1/100, step [94/390], train_loss = 2.018, train_acc = 40.395\n",
      "epoch 1/100, step [95/390], train_loss = 2.022, train_acc = 39.980\n",
      "epoch 1/100, step [96/390], train_loss = 2.022, train_acc = 39.835\n",
      "epoch 1/100, step [97/390], train_loss = 2.017, train_acc = 40.123\n",
      "epoch 1/100, step [98/390], train_loss = 2.014, train_acc = 40.251\n",
      "epoch 1/100, step [99/390], train_loss = 2.029, train_acc = 39.888\n",
      "epoch 1/100, step [100/390], train_loss = 2.015, train_acc = 40.106\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "train_loss_d, train_acc_d, test_loss_d, test_acc_d = [], [], [], []\n",
    "running_loss = []\n",
    "running_acc = []\n",
    "n_total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    # Total loss on all training sample\n",
    "    total_loss = []\n",
    "    # Total accuracy on all training sample\n",
    "    total_acc = []\n",
    "    for i, (data, labels) in enumerate(train_loader):\n",
    "        # Batch size: 10000 \n",
    "        # 1000000, 81\n",
    "        labels = labels.to(device, dtype = torch.long) # Change labels to long data type for cross entropy\n",
    "        data = data.to(device)\n",
    "        \n",
    "        # forward \n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Batch loss\n",
    "        running_loss.append(loss.item())\n",
    "\n",
    "        # Batch accuracy calculate\n",
    "        _, predicted = torch.max(outputs, 1) # Get prediction on batch (shape: batch_size)\n",
    "        batch_correct_predicted = (predicted == labels).sum().item() # Get number of true prediction on batch\n",
    "        running_acc.append(batch_correct_predicted/batch_size*100) # Append prediction accuracy \n",
    "        if i % 10 == 0:\n",
    "            # Calculate average train loss on 10000 batch\n",
    "            avg_train_loss = np.mean(running_loss)\n",
    "            running_loss.clear()\n",
    "            # Calculate average train accuracy on 10000 batch\n",
    "            avg_train_acc = np.mean(running_acc)\n",
    "            running_acc.clear()\n",
    "            # Adding batch loss to total loss\n",
    "            # Calculate average test loss on all val dataset\n",
    "            #avg_test_loss = get_test_loss_acc(model, criterion, val_loader)['loss']\n",
    "            # Calculate average train accuracy on all val dataset\n",
    "            #avg_test_acc = get_test_loss_acc(model, criterion, val_loader)['acc']\n",
    "            total_loss.append(avg_train_loss)\n",
    "            # Adding batch accuracy to total accuracy\n",
    "            total_acc.append(avg_train_acc)\n",
    "            # Adding data to plot after training\n",
    "            train_loss_d.append(avg_train_loss) \n",
    "            train_acc_d.append(avg_train_acc) \n",
    "            #test_loss_d.append(avg_test_loss) \n",
    "            #test_acc_d.append(avg_test_acc) \n",
    "            #print(f'epoch {epoch + 1}/{num_epochs}, step [{i+1}/{n_total_step}], train_loss = {avg_train_loss:.3f}, train_acc = {avg_train_acc:.3f}, test_loss = {avg_test_loss:.3f}, test_acc = {avg_test_acc:.3f}')\n",
    "            print(f'epoch {epoch + 1}/{num_epochs}, step [{i+1}/{n_total_step}], train_loss = {avg_train_loss:.3f}, train_acc = {avg_train_acc:.3f}')\n",
    "            # Write plot data to csv file\n",
    "            #plot_data = [i+1,avg_train_loss,avg_train_acc,avg_test_loss,avg_test_acc]\n",
    "            #writer.writerow(plot_data)\n",
    "    scheduler.step()\n",
    "    #print('Epoch: [{}/{}], train_Loss: {:.3f}, train_accuracy: {:.3f}'.format(epoch + 1, num_epochs, np.mean(total_loss), np.mean(total_acc)))\n",
    "    #PATH = '/home/jun/CICIDS2019/saved_model/ANN_' + str(epoch+1) + 'epoch.pth'\n",
    "    torch.save(model.state_dict(), PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
