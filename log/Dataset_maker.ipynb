{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 18:48:01,018\tINFO worker.py:1636 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "# Import library for load data\n",
    "import ray\n",
    "ray.init(num_cpus=8)\n",
    "import modin.pandas as pd\n",
    "#import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import csv\n",
    "# Import deeplearning library\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import copy\n",
    "import numpy as np \n",
    "import argparse\n",
    "import sys\n",
    "sys.path.append('/home/jun/DDoSDeepLearningProject/')\n",
    "from CustomFunction import *\n",
    "from model_define import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------PARAMETERS-------------\n",
      "Raw dataset folder PATH: /home/jun/DDoSDeepLearningProject/Dataset\n",
      "Fixed dataset (all attack) PATH: /home/jun/DDoSDeepLearningProject/dataset_all_attack\n",
      "DDoS dataset (DDoS attack only) PATH: /home/jun/DDoSDeepLearningProject/dataset_ddos\n"
     ]
    }
   ],
   "source": [
    "#----------------PARSE PARAMETER-----------------\n",
    "parser = argparse.ArgumentParser(description='This program will take raw dataset of CICIDS2017, CICIDS2018, CICIDS2019 and turn it into clean all_attack dataset and ddos only dataset')\n",
    "# parser.add_argument: Add parameter to program\n",
    "WORK_PATH = os.getcwd()\n",
    "parser.add_argument('--dataset', help='Raw dataset folder', default= '/home/jun/DDoSDeepLearningProject/Dataset')\n",
    "parser.add_argument('--fixed', help='Fixed dataset folder', default='/home/jun/DDoSDeepLearningProject/dataset_all_attack') \n",
    "parser.add_argument('--ddosonly', help='DDoS only dataset folder', default='/home/jun/DDoSDeepLearningProject/dataset_ddos') \n",
    "#args = parser.parse_args()\n",
    "args = parser.parse_args(args=['--dataset','/home/jun/DDoSDeepLearningProject/Dataset', '--fixed', '/home/jun/DDoSDeepLearningProject/dataset_all_attack', '--ddosonly', '/home/jun/DDoSDeepLearningProject/dataset_ddos'])\n",
    "#----------------Define variable based of args----------\n",
    "\n",
    "raw_dataset_PATH = args.dataset\n",
    "fixed_dataset_PATH = args.fixed\n",
    "ddos_dataset_PATH =  args.ddosonly\n",
    "os.makedirs(fixed_dataset_PATH, exist_ok=True)\n",
    "os.makedirs(ddos_dataset_PATH, exist_ok=True)\n",
    "# Make folder for validate data file\n",
    "print('-------------PARAMETERS-------------')\n",
    "print('Raw dataset folder PATH:',raw_dataset_PATH)\n",
    "print('Fixed dataset (all attack) PATH:', fixed_dataset_PATH)\n",
    "print('DDoS dataset (DDoS attack only) PATH:', ddos_dataset_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CICIDS2019\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2019/DrDoS_UDP.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2019/Syn.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2019/DrDoS_NetBIOS.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2019/UDPLag.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2019/TFTP.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2019/DrDoS_LDAP.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2019/DrDoS_MSSQL.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2019/DrDoS_SSDP.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2019/DrDoS_NTP.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2019/DrDoS_SNMP.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2019/DrDoS_DNS.csv\n",
      "CICIDS2017\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2017/Monday-WorkingHours.pcap_ISCX.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2017/Wednesday-workingHours.pcap_ISCX.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2017/Friday-WorkingHours-Morning.pcap_ISCX.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2017/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2017/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2017/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2017/Tuesday-WorkingHours.pcap_ISCX.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2017/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\n",
      "CICIDS2018\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2018/Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2018/Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2018/Friday-02-03-2018_TrafficForML_CICFlowMeter.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2018/Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2018/Friday-23-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2018/Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2018/Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2018/Friday-16-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2018/Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv\n",
      "\t/home/jun/DDoSDeepLearningProject/Dataset/CICIDS2018/Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv\n"
     ]
    }
   ],
   "source": [
    "folder = raw_dataset_PATH\n",
    "csv_file = csv_file_list(folder)\n",
    "for folder in csv_file.keys():\n",
    "    print(folder)\n",
    "    for file in csv_file[folder]:\n",
    "        print(f'\\t{file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CICIDS2019 columns: 88\n",
      "CICIDS2018 columns: 84 and 80\n",
      "CICIDS2017 columns: 85\n"
     ]
    }
   ],
   "source": [
    "CICIDS2019_columns = ['Unnamed: 0', 'Flow ID', 'Source IP', 'Source Port', 'Destination IP',\n",
    "                'Destination Port', 'Protocol', 'Timestamp', 'Flow Duration',\n",
    "                'Total Fwd Packets', 'Total Backward Packets',\n",
    "                'Total Length of Fwd Packets', 'Total Length of Bwd Packets',\n",
    "                'Fwd Packet Length Max', 'Fwd Packet Length Min',\n",
    "                'Fwd Packet Length Mean', 'Fwd Packet Length Std',\n",
    "                'Bwd Packet Length Max', 'Bwd Packet Length Min',\n",
    "                'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s',\n",
    "                'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n",
    "                'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std',\n",
    "                'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean',\n",
    "                'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags',\n",
    "                'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length',\n",
    "                'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s',\n",
    "                'Min Packet Length', 'Max Packet Length', 'Packet Length Mean',\n",
    "                'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count',\n",
    "                'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n",
    "                'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio',\n",
    "                'Average Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size',\n",
    "                'Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk',\n",
    "                'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk',\n",
    "                'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes',\n",
    "                'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
    "                'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward',\n",
    "                'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\n",
    "                'Idle Std', 'Idle Max', 'Idle Min', 'SimillarHTTP', 'Inbound', 'Label']\n",
    "\n",
    "CICIDS2018_columns = ['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port',\n",
    "                'Protocol', 'Timestamp', 'Flow Duration', 'Tot Fwd Pkts',\n",
    "                'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max',\n",
    "                'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std',\n",
    "                'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean',\n",
    "                'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean',\n",
    "                'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot',\n",
    "                'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min',\n",
    "                'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max',\n",
    "                'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags',\n",
    "                'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s',\n",
    "                'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean',\n",
    "                'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt',\n",
    "                'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt',\n",
    "                'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg',\n",
    "                'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg',\n",
    "                'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg',\n",
    "                'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts',\n",
    "                'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts',\n",
    "                'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts',\n",
    "                'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max',\n",
    "                'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n",
    "\n",
    "CICIDS2018_columns_fixed = ['Flow ID', 'Source IP', 'Source Port', 'Destination IP',\n",
    "                'Destination Port', 'Protocol', 'Timestamp', 'Flow Duration',\n",
    "                'Total Fwd Packets', 'Total Backward Packets',\n",
    "                'Total Length of Fwd Packets', 'Total Length of Bwd Packets',\n",
    "                'Fwd Packet Length Max', 'Fwd Packet Length Min',\n",
    "                'Fwd Packet Length Mean', 'Fwd Packet Length Std',\n",
    "                'Bwd Packet Length Max', 'Bwd Packet Length Min',\n",
    "                'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s',\n",
    "                'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n",
    "                'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std',\n",
    "                'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean',\n",
    "                'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags',\n",
    "                'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length',\n",
    "                'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s',\n",
    "                'Min Packet Length', 'Max Packet Length', 'Packet Length Mean',\n",
    "                'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count',\n",
    "                'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n",
    "                'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio',\n",
    "                'Average Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size',\n",
    "                'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk',\n",
    "                'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk',\n",
    "                'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes',\n",
    "                'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
    "                'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward',\n",
    "                'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\n",
    "                'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n",
    "\n",
    "CICIDS2018_columns_fixed_2 = [\n",
    "                'Destination Port', 'Protocol', 'Timestamp', 'Flow Duration',\n",
    "                'Total Fwd Packets', 'Total Backward Packets',\n",
    "                'Total Length of Fwd Packets', 'Total Length of Bwd Packets',\n",
    "                'Fwd Packet Length Max', 'Fwd Packet Length Min',\n",
    "                'Fwd Packet Length Mean', 'Fwd Packet Length Std',\n",
    "                'Bwd Packet Length Max', 'Bwd Packet Length Min',\n",
    "                'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s',\n",
    "                'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n",
    "                'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std',\n",
    "                'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean',\n",
    "                'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags',\n",
    "                'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length',\n",
    "                'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s',\n",
    "                'Min Packet Length', 'Max Packet Length', 'Packet Length Mean',\n",
    "                'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count',\n",
    "                'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n",
    "                'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio',\n",
    "                'Average Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size',\n",
    "                'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk',\n",
    "                'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk',\n",
    "                'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes',\n",
    "                'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
    "                'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward',\n",
    "                'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\n",
    "                'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n",
    "\n",
    "CICIDS2017_columns = ['Flow ID', 'Source IP', 'Source Port', 'Destination IP',\n",
    "                'Destination Port', 'Protocol', 'Timestamp', 'Flow Duration',\n",
    "                'Total Fwd Packets', 'Total Backward Packets',\n",
    "                'Total Length of Fwd Packets', 'Total Length of Bwd Packets',\n",
    "                'Fwd Packet Length Max', 'Fwd Packet Length Min',\n",
    "                'Fwd Packet Length Mean', 'Fwd Packet Length Std',\n",
    "                'Bwd Packet Length Max', 'Bwd Packet Length Min',\n",
    "                'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s',\n",
    "                'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n",
    "                'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std',\n",
    "                'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean',\n",
    "                'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags',\n",
    "                'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length',\n",
    "                'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s',\n",
    "                'Min Packet Length', 'Max Packet Length', 'Packet Length Mean',\n",
    "                'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count',\n",
    "                'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n",
    "                'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio',\n",
    "                'Average Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size',\n",
    "                'Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk',\n",
    "                'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk',\n",
    "                'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes',\n",
    "                'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
    "                'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward',\n",
    "                'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\n",
    "                'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n",
    "\n",
    "print(\"CICIDS2019 columns:\", len(CICIDS2019_columns))\n",
    "print(\"CICIDS2018 columns: {} and {}\".format(len(CICIDS2018_columns_fixed), len(CICIDS2018_columns_fixed_2)))\n",
    "print(\"CICIDS2017 columns:\", len(CICIDS2017_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------ANALYZE DATASET-------------\n",
      "Start loading folder CICIDS2019\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2019/DrDoS_UDP.csv\n",
      "DrDoS_UDP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: When using a pre-initialized Ray cluster, please ensure that the runtime env sets environment variable __MODIN_AUTOIMPORT_PANDAS__ to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2019/Syn.csv\n",
      "Syn\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2019/DrDoS_NetBIOS.csv\n",
      "DrDoS_NetBIOS\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2019/UDPLag.csv\n",
      "UDPLag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `read_*` implementation has mismatches with pandas:\n",
      "Data types of partitions are different! Please refer to the troubleshooting section of the Modin documentation to fix this issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2019/TFTP.csv\n",
      "TFTP\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2019/DrDoS_LDAP.csv\n",
      "DrDoS_LDAP\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2019/DrDoS_MSSQL.csv\n",
      "DrDoS_MSSQL\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2019/DrDoS_SSDP.csv\n",
      "DrDoS_SSDP\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2019/DrDoS_NTP.csv\n",
      "DrDoS_NTP\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2019/DrDoS_SNMP.csv\n",
      "DrDoS_SNMP\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2019/DrDoS_DNS.csv\n",
      "DrDoS_DNS\n",
      "\tDONE!\n",
      "Start loading folder CICIDS2017\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2017/Monday-WorkingHours.pcap_ISCX.csv\n",
      "Monday-WorkingHours\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2017/Wednesday-workingHours.pcap_ISCX.csv\n",
      "Wednesday-workingHours\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2017/Friday-WorkingHours-Morning.pcap_ISCX.csv\n",
      "Friday-WorkingHours-Morning\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2017/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\n",
      "Friday-WorkingHours-Afternoon-PortScan\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2017/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n",
      "Friday-WorkingHours-Afternoon-DDos\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2017/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\n",
      "Thursday-WorkingHours-Morning-WebAttacks\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2017/Tuesday-WorkingHours.pcap_ISCX.csv\n",
      "Tuesday-WorkingHours\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2017/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\n",
      "Thursday-WorkingHours-Afternoon-Infilteration\n",
      "\tDONE!\n",
      "Start loading folder CICIDS2018\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2018/Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "Thuesday-20-02-2018_TrafficForML_CICFlowMeter\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2018/Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "Wednesday-14-02-2018_TrafficForML_CICFlowMeter\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2018/Friday-02-03-2018_TrafficForML_CICFlowMeter.csv\n",
      "Friday-02-03-2018_TrafficForML_CICFlowMeter\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2018/Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "Wednesday-21-02-2018_TrafficForML_CICFlowMeter\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2018/Friday-23-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "Friday-23-02-2018_TrafficForML_CICFlowMeter\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2018/Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "Wednesday-28-02-2018_TrafficForML_CICFlowMeter\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2018/Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "Thursday-15-02-2018_TrafficForML_CICFlowMeter\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2018/Friday-16-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "Friday-16-02-2018_TrafficForML_CICFlowMeter\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2018/Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv\n",
      "Thursday-01-03-2018_TrafficForML_CICFlowMeter\n",
      "\tDONE!\n",
      "\tLoading /home/jun/DDoSDeepLearningProject/Dataset/CICIDS2018/Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "Thursday-22-02-2018_TrafficForML_CICFlowMeter\n",
      "\tDONE!\n",
      "ALL DONE!\n"
     ]
    }
   ],
   "source": [
    "print('-------------ANALYZE DATASET-------------')\n",
    "data = {}\n",
    "for dataset in csv_file.keys():\n",
    "    data_dict = {}\n",
    "    print(f\"Start loading folder {dataset}\")\n",
    "    for file in csv_file[dataset]:\n",
    "        print(f\"\\tLoading {file}\")\n",
    "        data_key =file.split('/')[-1].split('.')[0] \n",
    "        print(data_key)\n",
    "        data_dict.update({file.split('/')[-1].split('.')[0]:pd.read_csv(file, encoding='cp1252')})\n",
    "        print(\"\\tDONE!\")\n",
    "    data.update({dataset:data_dict})\n",
    "print(\"ALL DONE!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CICIDS2019\n",
      "\t DrDoS_UDP.csv have 88 columns\n",
      "\t Syn.csv have 88 columns\n",
      "\t DrDoS_NetBIOS.csv have 88 columns\n",
      "\t UDPLag.csv have 88 columns\n",
      "\t TFTP.csv have 88 columns\n",
      "\t DrDoS_LDAP.csv have 88 columns\n",
      "\t DrDoS_MSSQL.csv have 88 columns\n",
      "\t DrDoS_SSDP.csv have 88 columns\n",
      "\t DrDoS_NTP.csv have 88 columns\n",
      "\t DrDoS_SNMP.csv have 88 columns\n",
      "\t DrDoS_DNS.csv have 88 columns\n",
      "CICIDS2017\n",
      "\t Monday-WorkingHours.csv have 85 columns\n",
      "\t Wednesday-workingHours.csv have 85 columns\n",
      "\t Friday-WorkingHours-Morning.csv have 85 columns\n",
      "\t Friday-WorkingHours-Afternoon-PortScan.csv have 85 columns\n",
      "\t Friday-WorkingHours-Afternoon-DDos.csv have 85 columns\n",
      "\t Thursday-WorkingHours-Morning-WebAttacks.csv have 85 columns\n",
      "\t Tuesday-WorkingHours.csv have 85 columns\n",
      "\t Thursday-WorkingHours-Afternoon-Infilteration.csv have 85 columns\n",
      "CICIDS2018\n",
      "\t Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv have 84 columns\n",
      "\t Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv have 80 columns\n",
      "\t Friday-02-03-2018_TrafficForML_CICFlowMeter.csv have 80 columns\n",
      "\t Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv have 80 columns\n",
      "\t Friday-23-02-2018_TrafficForML_CICFlowMeter.csv have 80 columns\n",
      "\t Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv have 80 columns\n",
      "\t Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv have 80 columns\n",
      "\t Friday-16-02-2018_TrafficForML_CICFlowMeter.csv have 80 columns\n",
      "\t Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv have 80 columns\n",
      "\t Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv have 80 columns\n"
     ]
    }
   ],
   "source": [
    "for dataset, data_dict in data.items():\n",
    "    print(dataset)\n",
    "    for csv_name, csv_data in data_dict.items():\n",
    "        print(f\"\\t {csv_name}.csv have {len(csv_data.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix columns name of all dataset\n",
    "for dataset, data_dict in data.items():\n",
    "    for csv_name, csv_data in data_dict.items():\n",
    "        csv_data = fix_columns_name(csv_data)\n",
    "for csv_name, csv_data in data['CICIDS2018'].items():\n",
    "    try:\n",
    "        csv_data.columns = CICIDS2018_columns_fixed\n",
    "    except:\n",
    "        csv_data.columns = CICIDS2018_columns_fixed_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop Thursday-WorkingHours-Morning-WebAttacks because of error label\n",
      "CICIDS2019\n",
      "\t DrDoS_UDP.csv have labels: {'BENIGN', 'DrDoS_UDP'}\n",
      "\t Syn.csv have labels: {'Syn', 'BENIGN'}\n",
      "\t DrDoS_NetBIOS.csv have labels: {'DrDoS_NetBIOS', 'BENIGN'}\n",
      "\t UDPLag.csv have labels: {'BENIGN', 'UDP-lag', 'WebDDoS'}\n",
      "\t TFTP.csv have labels: {'BENIGN', 'TFTP'}\n",
      "\t DrDoS_LDAP.csv have labels: {'BENIGN', 'DrDoS_LDAP'}\n",
      "\t DrDoS_MSSQL.csv have labels: {'BENIGN', 'DrDoS_MSSQL'}\n",
      "\t DrDoS_SSDP.csv have labels: {'DrDoS_SSDP', 'BENIGN'}\n",
      "\t DrDoS_NTP.csv have labels: {'DrDoS_NTP', 'BENIGN'}\n",
      "\t DrDoS_SNMP.csv have labels: {'BENIGN', 'DrDoS_SNMP'}\n",
      "\t DrDoS_DNS.csv have labels: {'BENIGN', 'DrDoS_DNS'}\n",
      "CICIDS2017\n",
      "\t Monday-WorkingHours.csv have labels: {'BENIGN'}\n",
      "\t Wednesday-workingHours.csv have labels: {'DoS Slowhttptest', 'DoS slowloris', 'Heartbleed', 'BENIGN', 'DoS Hulk', 'DoS GoldenEye'}\n",
      "\t Friday-WorkingHours-Morning.csv have labels: {'Bot', 'BENIGN'}\n",
      "\t Friday-WorkingHours-Afternoon-PortScan.csv have labels: {'PortScan', 'BENIGN'}\n",
      "\t Friday-WorkingHours-Afternoon-DDos.csv have labels: {'BENIGN', 'DDoS'}\n",
      "\t Tuesday-WorkingHours.csv have labels: {'SSH-Patator', 'BENIGN', 'FTP-Patator'}\n",
      "\t Thursday-WorkingHours-Afternoon-Infilteration.csv have labels: {'Infiltration', 'BENIGN'}\n",
      "CICIDS2018\n",
      "\t Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv have labels: {'Benign', 'DDoS attacks-LOIC-HTTP'}\n",
      "\t Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv have labels: {'SSH-Bruteforce', 'Benign', 'FTP-BruteForce'}\n",
      "\t Friday-02-03-2018_TrafficForML_CICFlowMeter.csv have labels: {'Benign', 'Bot'}\n",
      "\t Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv have labels: {'Benign', 'DDOS attack-LOIC-UDP', 'DDOS attack-HOIC'}\n",
      "\t Friday-23-02-2018_TrafficForML_CICFlowMeter.csv have labels: {'Brute Force -XSS', 'Benign', 'Brute Force -Web', 'SQL Injection'}\n",
      "\t Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv have labels: {'Label', 'Benign', 'Infilteration'}\n",
      "\t Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv have labels: {'Benign', 'DoS attacks-Slowloris', 'DoS attacks-GoldenEye'}\n",
      "\t Friday-16-02-2018_TrafficForML_CICFlowMeter.csv have labels: {'Label', 'Benign', 'DoS attacks-Hulk', 'DoS attacks-SlowHTTPTest'}\n",
      "\t Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv have labels: {'Label', 'Benign', 'Infilteration'}\n",
      "\t Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv have labels: {'Brute Force -XSS', 'Benign', 'Brute Force -Web', 'SQL Injection'}\n"
     ]
    }
   ],
   "source": [
    "print('Drop Thursday-WorkingHours-Morning-WebAttacks because of error label')\n",
    "del data['CICIDS2017']['Thursday-WorkingHours-Morning-WebAttacks']\n",
    "for dataset, data_dict in data.items():\n",
    "    print(dataset)\n",
    "    for csv_name, csv_data in data_dict.items():\n",
    "        print(f\"\\t {csv_name}.csv have labels: {set(csv_data['Label'])}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CICIDS2019\n",
      "\tDrDoS_UDP,csv not included 0 columns: []\n",
      "\tSyn,csv not included 0 columns: []\n",
      "\tDrDoS_NetBIOS,csv not included 0 columns: []\n",
      "\tUDPLag,csv not included 0 columns: []\n",
      "\tTFTP,csv not included 0 columns: []\n",
      "\tDrDoS_LDAP,csv not included 0 columns: []\n",
      "\tDrDoS_MSSQL,csv not included 0 columns: []\n",
      "\tDrDoS_SSDP,csv not included 0 columns: []\n",
      "\tDrDoS_NTP,csv not included 0 columns: []\n",
      "\tDrDoS_SNMP,csv not included 0 columns: []\n",
      "\tDrDoS_DNS,csv not included 0 columns: []\n",
      "CICIDS2017\n",
      "\tMonday-WorkingHours,csv not included 3 columns: ['Unnamed: 0', 'SimillarHTTP', 'Inbound']\n",
      "\tWednesday-workingHours,csv not included 3 columns: ['Unnamed: 0', 'SimillarHTTP', 'Inbound']\n",
      "\tFriday-WorkingHours-Morning,csv not included 3 columns: ['Unnamed: 0', 'SimillarHTTP', 'Inbound']\n",
      "\tFriday-WorkingHours-Afternoon-PortScan,csv not included 3 columns: ['Unnamed: 0', 'SimillarHTTP', 'Inbound']\n",
      "\tFriday-WorkingHours-Afternoon-DDos,csv not included 3 columns: ['Unnamed: 0', 'SimillarHTTP', 'Inbound']\n",
      "\tTuesday-WorkingHours,csv not included 3 columns: ['Unnamed: 0', 'SimillarHTTP', 'Inbound']\n",
      "\tThursday-WorkingHours-Afternoon-Infilteration,csv not included 3 columns: ['Unnamed: 0', 'SimillarHTTP', 'Inbound']\n",
      "CICIDS2018\n",
      "\tThuesday-20-02-2018_TrafficForML_CICFlowMeter,csv not included 4 columns: ['Unnamed: 0', 'Fwd Header Length.1', 'SimillarHTTP', 'Inbound']\n",
      "\tWednesday-14-02-2018_TrafficForML_CICFlowMeter,csv not included 8 columns: ['Unnamed: 0', 'Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1', 'SimillarHTTP', 'Inbound']\n",
      "\tFriday-02-03-2018_TrafficForML_CICFlowMeter,csv not included 8 columns: ['Unnamed: 0', 'Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1', 'SimillarHTTP', 'Inbound']\n",
      "\tWednesday-21-02-2018_TrafficForML_CICFlowMeter,csv not included 8 columns: ['Unnamed: 0', 'Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1', 'SimillarHTTP', 'Inbound']\n",
      "\tFriday-23-02-2018_TrafficForML_CICFlowMeter,csv not included 8 columns: ['Unnamed: 0', 'Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1', 'SimillarHTTP', 'Inbound']\n",
      "\tWednesday-28-02-2018_TrafficForML_CICFlowMeter,csv not included 8 columns: ['Unnamed: 0', 'Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1', 'SimillarHTTP', 'Inbound']\n",
      "\tThursday-15-02-2018_TrafficForML_CICFlowMeter,csv not included 8 columns: ['Unnamed: 0', 'Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1', 'SimillarHTTP', 'Inbound']\n",
      "\tFriday-16-02-2018_TrafficForML_CICFlowMeter,csv not included 8 columns: ['Unnamed: 0', 'Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1', 'SimillarHTTP', 'Inbound']\n",
      "\tThursday-01-03-2018_TrafficForML_CICFlowMeter,csv not included 8 columns: ['Unnamed: 0', 'Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1', 'SimillarHTTP', 'Inbound']\n",
      "\tThursday-22-02-2018_TrafficForML_CICFlowMeter,csv not included 8 columns: ['Unnamed: 0', 'Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1', 'SimillarHTTP', 'Inbound']\n"
     ]
    }
   ],
   "source": [
    "for dataset, data_dict in data.items():\n",
    "    print(dataset)\n",
    "    for csv_name, csv_data in data_dict.items():\n",
    "        this_columns = csv_data.columns\n",
    "        not_included = []\n",
    "        for column in CICIDS2019_columns:\n",
    "            if column not in this_columns:\n",
    "                not_included.append(column)\n",
    "        print(f\"\\t{csv_name},csv not included {len(not_included)} columns: {not_included}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CICIDS2019\n",
      "\t Drop 8 columns: ['Unnamed: 0', 'Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1', 'SimillarHTTP', 'Inbound'] from DrDoS_UDP.csv\n",
      "\t Drop 8 columns: ['Unnamed: 0', 'Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1', 'SimillarHTTP', 'Inbound'] from Syn.csv\n",
      "\t Drop 8 columns: ['Unnamed: 0', 'Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1', 'SimillarHTTP', 'Inbound'] from DrDoS_NetBIOS.csv\n",
      "\t Drop 8 columns: ['Unnamed: 0', 'Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1', 'SimillarHTTP', 'Inbound'] from UDPLag.csv\n",
      "\t Drop 8 columns: ['Unnamed: 0', 'Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1', 'SimillarHTTP', 'Inbound'] from TFTP.csv\n",
      "\t Drop 8 columns: ['Unnamed: 0', 'Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1', 'SimillarHTTP', 'Inbound'] from DrDoS_LDAP.csv\n",
      "\t Drop 8 columns: ['Unnamed: 0', 'Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1', 'SimillarHTTP', 'Inbound'] from DrDoS_MSSQL.csv\n",
      "\t Drop 8 columns: ['Unnamed: 0', 'Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1', 'SimillarHTTP', 'Inbound'] from DrDoS_SSDP.csv\n",
      "\t Drop 8 columns: ['Unnamed: 0', 'Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1', 'SimillarHTTP', 'Inbound'] from DrDoS_NTP.csv\n",
      "\t Drop 8 columns: ['Unnamed: 0', 'Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1', 'SimillarHTTP', 'Inbound'] from DrDoS_SNMP.csv\n",
      "\t Drop 8 columns: ['Unnamed: 0', 'Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1', 'SimillarHTTP', 'Inbound'] from DrDoS_DNS.csv\n",
      "CICIDS2017\n",
      "\t Drop 5 columns: ['Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1'] from Monday-WorkingHours.csv\n",
      "\t Drop 5 columns: ['Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1'] from Wednesday-workingHours.csv\n",
      "\t Drop 5 columns: ['Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1'] from Friday-WorkingHours-Morning.csv\n",
      "\t Drop 5 columns: ['Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1'] from Friday-WorkingHours-Afternoon-PortScan.csv\n",
      "\t Drop 5 columns: ['Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1'] from Friday-WorkingHours-Afternoon-DDos.csv\n",
      "\t Drop 5 columns: ['Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1'] from Tuesday-WorkingHours.csv\n",
      "\t Drop 5 columns: ['Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Fwd Header Length.1'] from Thursday-WorkingHours-Afternoon-Infilteration.csv\n",
      "CICIDS2018\n",
      "\t Drop 4 columns: ['Flow ID', 'Source IP', 'Source Port', 'Destination IP'] from Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "\t Drop 0 columns: [] from Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "\t Drop 0 columns: [] from Friday-02-03-2018_TrafficForML_CICFlowMeter.csv\n",
      "\t Drop 0 columns: [] from Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "\t Drop 0 columns: [] from Friday-23-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "\t Drop 0 columns: [] from Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "\t Drop 0 columns: [] from Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "\t Drop 0 columns: [] from Friday-16-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "\t Drop 0 columns: [] from Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv\n",
      "\t Drop 0 columns: [] from Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv\n"
     ]
    }
   ],
   "source": [
    "for dataset, data_dict in data.items():\n",
    "    print(dataset)\n",
    "    for csv_name, csv_data in data_dict.items():\n",
    "        this_columns = csv_data.columns\n",
    "        not_included = []\n",
    "        for column in this_columns:\n",
    "            if column not in CICIDS2018_columns_fixed_2:\n",
    "                not_included.append(column)\n",
    "        print(f\"\\t Drop {len(not_included)} columns: {not_included} from {csv_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CICIDS2019_drop_list = ['Unnamed: 0', 'Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Timestamp', 'Fwd Header Length.1', 'SimillarHTTP', 'Inbound']\n",
    "CICIDS2018_drop_list = ['Destination Port', 'Timestamp']\n",
    "CICIDS2018_drop_list_2 = ['Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Timestamp']\n",
    "CICIDS2017_drop_list = ['Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Timestamp', 'Fwd Header Length.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thuesday-20-02-2018_TrafficForML_CICFlowMeter have: 78 columns\n",
      "Wednesday-14-02-2018_TrafficForML_CICFlowMeter have: 78 columns\n",
      "Friday-02-03-2018_TrafficForML_CICFlowMeter have: 78 columns\n",
      "Wednesday-21-02-2018_TrafficForML_CICFlowMeter have: 78 columns\n",
      "Friday-23-02-2018_TrafficForML_CICFlowMeter have: 78 columns\n",
      "Wednesday-28-02-2018_TrafficForML_CICFlowMeter have: 78 columns\n",
      "Thursday-15-02-2018_TrafficForML_CICFlowMeter have: 78 columns\n",
      "Friday-16-02-2018_TrafficForML_CICFlowMeter have: 78 columns\n",
      "Thursday-01-03-2018_TrafficForML_CICFlowMeter have: 78 columns\n",
      "Thursday-22-02-2018_TrafficForML_CICFlowMeter have: 78 columns\n"
     ]
    }
   ],
   "source": [
    "for csv_name, csv_data in data['CICIDS2018'].items():\n",
    "    try:\n",
    "        csv_data.drop(CICIDS2018_drop_list_2, inplace=True, axis=1)\n",
    "        print(f'{csv_name} have: {len(csv_data.columns)} columns')\n",
    "    except:\n",
    "        csv_data.drop(CICIDS2018_drop_list, inplace=True, axis=1)\n",
    "        print(f\"Error {csv_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monday-WorkingHours have: 78 columns\n",
      "Wednesday-workingHours have: 78 columns\n",
      "Friday-WorkingHours-Morning have: 78 columns\n",
      "Friday-WorkingHours-Afternoon-PortScan have: 78 columns\n",
      "Friday-WorkingHours-Afternoon-DDos have: 78 columns\n",
      "Tuesday-WorkingHours have: 78 columns\n",
      "Thursday-WorkingHours-Afternoon-Infilteration have: 78 columns\n"
     ]
    }
   ],
   "source": [
    "for csv_name, csv_data in data['CICIDS2017'].items():\n",
    "    try:\n",
    "        csv_data.drop(CICIDS2017_drop_list, inplace=True, axis=1)\n",
    "        print(f'{csv_name} have: {len(csv_data.columns)} columns')\n",
    "    except:\n",
    "        print(f\"Error {csv_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv_name, csv_data in data['CICIDS2019'].items():\n",
    "    try:\n",
    "        csv_data.drop(CICIDS2019_drop_list, inplace=True, axis=1)\n",
    "    except:\n",
    "        print(f\"Error {csv_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to CICIDS2019\n",
      "Writing to CICIDS2017\n",
      "Writing to CICIDS2018\n"
     ]
    }
   ],
   "source": [
    "merged = {}\n",
    "for dataset, data_dict in data.items():\n",
    "    merged.update({dataset:pd.concat(data_dict.values(), ignore_index=True, sort=False)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CICIDS2018_labels = {'DoS attacks-SlowHTTPTest':'DoS Slowhttptest', 'DoS attacks-GoldenEye':'DoS GoldenEye', 'DoS attacks-Slowloris':'DoS slowloris','DoS attacks-Hulk':'DoS Hulk', 'Benign': 'BENIGN'}\n",
    "for label_old, label_new in CICIDS2018_labels.items():\n",
    "        merged['CICIDS2018']['Label'] = merged['CICIDS2018']['Label'].replace(label_old, label_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t CICIDS2019 (all_type_attack) have labels: {'DrDoS_MSSQL', 'WebDDoS', 'Syn', 'DrDoS_SNMP', 'DrDoS_LDAP', 'DrDoS_DNS', 'BENIGN', 'DrDoS_NetBIOS', 'UDP-lag', 'DrDoS_NTP', 'DrDoS_SSDP', 'TFTP', 'DrDoS_UDP'}\n",
      "\t CICIDS2017 (all_type_attack) have labels: {'DDoS', 'Heartbleed', 'Infiltration', 'DoS GoldenEye', 'Bot', 'FTP-Patator', 'BENIGN', 'SSH-Patator', 'DoS slowloris', 'DoS Hulk', 'DoS Slowhttptest', 'PortScan'}\n",
      "\t CICIDS2018 (all_type_attack) have labels: {'DDOS attack-HOIC', 'Bot', 'DoS GoldenEye', 'Brute Force -XSS', 'Label', 'Infilteration', 'Brute Force -Web', 'BENIGN', 'DoS Slowhttptest', 'DDoS attacks-LOIC-HTTP', 'DoS slowloris', 'FTP-BruteForce', 'SSH-Bruteforce', 'DoS Hulk', 'DDOS attack-LOIC-UDP', 'SQL Injection'}\n"
     ]
    }
   ],
   "source": [
    "for dataset, data_merged in merged.items():\n",
    "    if dataset == 'CICIDS2018':\n",
    "        merged['CICIDS2018'] = merged['CICIDS2018'].loc[merged['CICIDS2018']['Label'].isin('Label')]\n",
    "    print(f\"\\t {dataset} (all_type_attack) have labels: {set(data_merged['Label'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 16:37:33,521\tWARNING worker.py:2019 -- WARNING: 32 PYTHON worker processes have been started on node: f139b3d6ed8a910cf5b64812d90245752783037a5f207416f9750c3f with address: 202.25.82.68. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\n"
     ]
    }
   ],
   "source": [
    "ddos_labels = {\n",
    "    'CICIDS2019': ['Syn', 'DrDoS_NetBIOS', 'DrDoS_SNMP', 'DrDoS_DNS', 'DrDoS_LDAP', 'DrDoS_UDP', 'UDP-lag', 'DrDoS_NTP', 'BENIGN', 'WebDDoS', 'DrDoS_MSSQL', 'DrDoS_SSDP', 'TFTP'],\n",
    "    'CICIDS2018' : ['DDOS attack-LOIC-UDP', 'BENIGN', 'DoS Slowhttptest', 'DoS slowloris', 'DoS GoldenEye', 'DDOS attack-HOIC', 'DoS Hulk', 'DDoS attacks-LOIC-HTTP'],\n",
    "    'CICIDS2017' : ['BENIGN', 'DoS Slowhttptest', 'DoS slowloris', 'DoS GoldenEye', 'DDoS', 'DoS Hulk']\n",
    "}\n",
    "ddos_only = {}\n",
    "for dataset, data_ddos in merged.items():\n",
    "    ddos_only.update({dataset:data_ddos.loc[data_ddos['Label'].isin(ddos_labels[dataset])]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t CICIDS2019 (ddos_only) have labels: {'DrDoS_MSSQL', 'WebDDoS', 'Syn', 'DrDoS_SNMP', 'DrDoS_LDAP', 'DrDoS_DNS', 'BENIGN', 'DrDoS_NetBIOS', 'UDP-lag', 'DrDoS_NTP', 'DrDoS_SSDP', 'TFTP', 'DrDoS_UDP'}\n",
      "\t CICIDS2017 (ddos_only) have labels: {'DDoS', 'DoS GoldenEye', 'BENIGN', 'DoS slowloris', 'DoS Hulk', 'DoS Slowhttptest'}\n",
      "\t CICIDS2018 (ddos_only) have labels: {'DDOS attack-HOIC', 'DoS GoldenEye', 'BENIGN', 'DoS Slowhttptest', 'DDoS attacks-LOIC-HTTP', 'DoS slowloris', 'DoS Hulk', 'DDOS attack-LOIC-UDP'}\n"
     ]
    }
   ],
   "source": [
    "for dataset, data_merged in ddos_only.items():\n",
    "    print(f\"\\t {dataset} (ddos_only) have labels: {set(data_merged['Label'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to CICIDS2019\n",
      "Writing to /home/jun/DDoSDeepLearningProject/dataset_all_attackCICIDS2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 61912 MiB, 813 objects, write throughput 899 MiB/s.\n",
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 63396 MiB, 833 objects, write throughput 907 MiB/s.\n",
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 67784 MiB, 894 objects, write throughput 930 MiB/s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL DONE!\n",
      "Writing to CICIDS2017\n",
      "Writing to /home/jun/DDoSDeepLearningProject/dataset_all_attackCICIDS2017.csv\n",
      "ALL DONE!\n",
      "Writing to CICIDS2018\n",
      "Writing to /home/jun/DDoSDeepLearningProject/dataset_all_attackCICIDS2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 138464 MiB, 1339 objects, write throughput 1026 MiB/s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL DONE!\n"
     ]
    }
   ],
   "source": [
    "for dataset, data_merged in merged.items():\n",
    "    print('Writing to {}'.format(dataset))\n",
    "    merged_PATH =fixed_dataset_PATH + '/' + dataset + '.csv'\n",
    "    print(f'Writing to {merged_PATH}')\n",
    "    data_merged.to_csv(merged_PATH,index=False) \n",
    "    print('ALL DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, data_merged in ddos_only.items():\n",
    "    print('Writing to {}'.format(dataset))\n",
    "    merged_PATH =ddos_dataset_PATH + '/' + dataset + '.csv'\n",
    "    print(f'Writing to {merged_PATH}')\n",
    "    data_merged.to_csv(merged_PATH,index=False) \n",
    "    print('ALL DONE!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
